{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank('en')  # create blank Language class\n",
    "print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['REFNO', 'PNR', 'TTIME', 'SRC', 'DES', 'AGENT', 'PASSENGER', 'FLTNO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the parser to the pipeline if it doesn't exist\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "\n",
    "if 'parser' not in nlp.pipe_names:\n",
    "    parser = nlp.create_pipe('parser')\n",
    "    nlp.add_pipe(parser, first=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    parser = nlp.get_pipe('parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    ner.add_label(label)\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n"
     ]
    }
   ],
   "source": [
    "if model is None:\n",
    "    optimizer = nlp.begin_training()\n",
    "else:\n",
    "    # Note that 'begin_training' initializes the models, so it'll zero out\n",
    "    # existing entity types.\n",
    "    optimizer = nlp.entity.create_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    ## Booking ID Samples\n",
    "    \n",
    "    (\"Booking Id: NF22696100810981\", {\n",
    "        'entities': [(13, 28, 'REFNO')]\n",
    "    }),\n",
    "\n",
    "    (\"Booking Id: NF22695116846185\", {\n",
    "        'entities': [(13, 28, 'REFNO')]\n",
    "    }),\n",
    "\n",
    "    (\"Booking Id: NF22995132466090\", {\n",
    "        'entities': [(13, 28, 'REFNO')]\n",
    "    }),\n",
    "\n",
    "    (\"Booking Id: NF22996135146142\", {\n",
    "        'entities': [(13, 28, 'REFNO')]\n",
    "    }),\n",
    "    \n",
    "    ## Time and Date Samples\n",
    "\n",
    "    (\"17:00 hrs, 18 Mar\", {\n",
    "        'entities': [(0, 17, 'TTIME')]\n",
    "    }),\n",
    "\n",
    "    (\"19:45 hrs, 18 Mar\", {\n",
    "        'entities': [(0, 17, 'TTIME')]\n",
    "    }),\n",
    "\n",
    "    (\"07:15 hrs, 03 Feb\", {\n",
    "        'entities': [(0, 17, 'TTIME')]\n",
    "    }),\n",
    "\n",
    "    (\"10:05 hrs, 03 Feb\", {\n",
    "        'entities': [(0, 17, 'TTIME')]\n",
    "    }),\n",
    "\n",
    "    (\"08:35 hrs, 18 Aug\", {\n",
    "        'entities': [(0, 17, 'TTIME')]\n",
    "    }),\n",
    "\n",
    "    (\"10:55 hrs, 18 Aug\", {\n",
    "        'entities': [(0, 17, 'TTIME')]\n",
    "    }),\n",
    "    \n",
    "    ## Flight Number Samples\n",
    "\n",
    "    (\"G8-118\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"G8-557\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"G8-2847\", {\n",
    "        'entities': [(0, 7, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"G8-284/ 4427\", {\n",
    "        'entities': [(0, 12, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"6E-3794/ 154\", {\n",
    "        'entities': [(0, 12, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "\n",
    "    (\"6E-606\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "\n",
    "    (\"G8-557\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "\n",
    "    (\"SG-185\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"6E-528\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"I5-247\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"I5-722\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"G6-142\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"G6-411\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"UK-817\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "    (\"AI-503\", {\n",
    "        'entities': [(0, 6, 'FLTNO')]\n",
    "    }),\n",
    "\n",
    "\n",
    "    (\"1. Shahrukh Khan, Adult\", {\n",
    "        'entities': [(3, 16, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"2. Ramesh Natarajan, Adult\", {\n",
    "        'entities': [(3, 19, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"1. Ranbir Kapoor, Adult\", {\n",
    "        'entities': [(3, 16, 'PASSENGER')]\n",
    "    }),\n",
    "    (\"2. Vivek Kumar, Child\", {\n",
    "        'entities': [(3, 14, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"2. Manohar P, Adult\", {\n",
    "        'entities': [(3, 12, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"1. Vinay I, Child\", {\n",
    "        'entities': [(3, 10, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"3. Kavita Venkat, Adult\", {\n",
    "        'entities': [(3, 16, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"3. Nitin Datta, Adult\", {\n",
    "        'entities': [(3, 14, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"1. Aditya Khar, Child\", {\n",
    "        'entities': [(3, 14, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"2. Abhishek Khare, Adult\", {\n",
    "        'entities': [(3, 17, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"3. Manish Sharma, Adult\", {\n",
    "        'entities': [(3, 16, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"4. Virat Kohli, Child\", {\n",
    "        'entities': [(3, 14, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"2. Vivek Kumar, Child\", {\n",
    "        'entities': [(3, 14, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    (\"2. Mr. MS Dhoni, Adult\", {\n",
    "        'entities': [(3, 15, 'PASSENGER')]\n",
    "    }),\n",
    "\n",
    "    ## Source and Destination\n",
    "    \n",
    "    (\"DELHI TO PUNE\", {\n",
    "        'entities': [(0, 5, 'SRC'), (9, 13, 'DES')]\n",
    "    }),\n",
    "\n",
    "    (\"PUNE TO DELHI\", {\n",
    "        'entities': [(0, 4, 'SRC'), (8, 13, 'DES')]\n",
    "    }),\n",
    "\n",
    "    (\"BANGALORE TO CHENNAI\", {\n",
    "        'entities': [(0, 9, 'SRC'), (13, 20, 'DES')]\n",
    "    }),\n",
    "\n",
    "    (\"DELHI TO CHENNAI \", {\n",
    "        'entities': [(0, 5, 'SRC'), (9, 16, 'DES')]\n",
    "    }),\n",
    "\n",
    "    (\"CHENNAI TO DELHI\", {\n",
    "        'entities': [(0, 7, 'SRC'), (11, 16, 'DES')]\n",
    "    }),\n",
    "    \n",
    "    (\"EDYTGT\", {\n",
    "        'entities': [(0, 6, 'PNR')]\n",
    "    }),\n",
    "\n",
    "    (\"AGARTALA TO JAIPUR\", {\n",
    "        'entities': [(0, 8, 'SRC'), (12, 18, 'DES')]\n",
    "    }),\n",
    "    \n",
    "    ## PNR no. samples\n",
    "\n",
    "    (\"ZH17NW\", {\n",
    "        'entities': [(0, 6, 'PNR')]\n",
    "    }),\n",
    "\n",
    "    (\"E758YP\", {\n",
    "        'entities': [(0, 6, 'PNR')]\n",
    "    }),\n",
    "\n",
    "    (\"MI7WUQ\", {\n",
    "        'entities': [(0, 6, 'PNR')]\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 10.549747785837294}\n",
      "Losses {'ner': 6.241883490537475}\n",
      "Losses {'ner': 3.2938905496245527}\n",
      "Losses {'ner': 1.8608073022860672}\n",
      "Losses {'ner': 0.745354686826578}\n",
      "Losses {'ner': 2.973457039807228}\n",
      "Losses {'ner': 0.16240438385611708}\n",
      "Losses {'ner': 0.3897034038458866}\n",
      "Losses {'ner': 0.1437818985121399}\n",
      "Losses {'ner': 2.154121585117668}\n",
      "Losses {'ner': 0.07933119703004406}\n",
      "Losses {'ner': 0.16593106216875952}\n",
      "Losses {'ner': 0.0008843289033693877}\n",
      "Losses {'ner': 0.00039962452072807346}\n",
      "Losses {'ner': 0.06327187291178601}\n",
      "Losses {'ner': 3.4929007310118904e-05}\n",
      "Losses {'ner': 0.34780144206170177}\n",
      "Losses {'ner': 1.1199900644070875e-07}\n",
      "Losses {'ner': 0.00015058464234437538}\n",
      "Losses {'ner': 3.1178815152352954e-06}\n"
     ]
    }
   ],
   "source": [
    "n_iter = 20\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.35,\n",
    "                       losses=losses)\n",
    "        print('Losses', losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLTNO AI-48\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"AI-48\")\n",
    "for ent in doc1.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLTNO SG-185\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"SG-185\")\n",
    "for ent in doc2.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLTNO 6E-1854\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(\"6E-1854\")\n",
    "for ent in doc3.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC PUNE\n",
      "DES CHENNAI\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(\"PUNE TO CHENNAI\")\n",
    "for ent in doc4.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC CHANDIGARH\n",
      "DES HYDERABAD\n"
     ]
    }
   ],
   "source": [
    "doc5 = nlp(\"CHANDIGARH TO HYDERABAD\")\n",
    "for ent in doc5.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC DELHI\n",
      "DES BANGALORE\n"
     ]
    }
   ],
   "source": [
    "doc6 = nlp(\"DELHI TO BANGALORE\")\n",
    "for ent in doc6.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC Brian\n"
     ]
    }
   ],
   "source": [
    "doc7 = nlp(\"2. Brian Lara, Adult\")\n",
    "for ent in doc7.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC Ricky\n"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(\"1. Ricky Ponting, Adult\")\n",
    "for ent in doc8.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC Sachin\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(\"3. Sachin Tendulkar, Adult\")\n",
    "for ent in doc9.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNR KB6RAE\n"
     ]
    }
   ],
   "source": [
    "doc10 = nlp(\"KB6RAE\")\n",
    "for ent in doc10.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNR PWRHSO\n"
     ]
    }
   ],
   "source": [
    "doc11 = nlp(\"PWRHSO\")\n",
    "for ent in doc11.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNR KB6RAE\n"
     ]
    }
   ],
   "source": [
    "doc11 = nlp(\"KB6RAE\")\n",
    "for ent in doc11.ents:\n",
    "    print(ent.label_, ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
